{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a8a9a856-1e3b-47ee-a086-8dd2d84717f4",
   "metadata": {},
   "source": [
    "# Federated Learning Algorithm Prototype\n",
    "## PFL-Research Framework by Apple\n",
    "#### Alian Haidar ahaidar@apple.com\n",
    "\n",
    "Dataset Used: FLAIR "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec452885-83ff-4f33-b404-a36c426c77fc",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b056bda-83f1-420f-b48f-cdabf0643a34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Downloading torch-2.3.0-cp312-none-macosx_11_0_arm64.whl.metadata (26 kB)\n",
      "Collecting filelock (from torch)\n",
      "  Downloading filelock-3.14.0-py3-none-any.whl.metadata (2.8 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /Users/alian/anaconda3/envs/cits5508-2024/lib/python3.12/site-packages (from torch) (4.10.0)\n",
      "Collecting sympy (from torch)\n",
      "  Using cached sympy-1.12-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: networkx in /Users/alian/anaconda3/envs/cits5508-2024/lib/python3.12/site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in /Users/alian/anaconda3/envs/cits5508-2024/lib/python3.12/site-packages (from torch) (3.1.3)\n",
      "Collecting fsspec (from torch)\n",
      "  Using cached fsspec-2024.3.1-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/alian/anaconda3/envs/cits5508-2024/lib/python3.12/site-packages (from jinja2->torch) (2.1.5)\n",
      "Collecting mpmath>=0.19 (from sympy->torch)\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Downloading torch-2.3.0-cp312-none-macosx_11_0_arm64.whl (61.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hDownloading filelock-3.14.0-py3-none-any.whl (12 kB)\n",
      "Using cached fsspec-2024.3.1-py3-none-any.whl (171 kB)\n",
      "Using cached sympy-1.12-py3-none-any.whl (5.7 MB)\n",
      "Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Installing collected packages: mpmath, sympy, fsspec, filelock, torch\n",
      "Successfully installed filelock-3.14.0 fsspec-2024.3.1 mpmath-1.3.0 sympy-1.12 torch-2.3.0\n"
     ]
    }
   ],
   "source": [
    "!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "267fa5ce-4eb9-41d8-9273-09440882937d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "import torch\n",
    "import nest_asyncio\n",
    "\n",
    "\n",
    "nest_asyncio.apply()\n",
    "torch.random.manual_seed(1)\n",
    "np.random.seed(1)\n",
    "\n",
    "from pfl.model.pytorch import PyTorchModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed0d9818-bd1b-43ae-bd82-5a1d25c18e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "from common import (get_multi_hot_targets, get_label_mapping, get_user_num_images)\n",
    "\n",
    "hdf5_path = 'flair_federated_small.hdf5'\n",
    "# A dictionary mapping class name to an output index.\n",
    "classes = get_label_mapping(hdf5_path, use_fine_grained_labels=False)\n",
    "num_classes = len(classes)\n",
    "\n",
    "# A dictionary mapping each user id to number of images.\n",
    "user_num_images = get_user_num_images(hdf5_path, 'train')\n",
    "user_ids = sorted(list(user_num_images.keys()))\n",
    "\n",
    "display('Coarse grained classes in FLAIR:')\n",
    "display((classes))\n",
    "display('User dataset sizes statistics')\n",
    "display(pd.Series(user_num_images.values()).describe().apply(\"{0:.1f}\".format))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cbb1cbc-5a14-4503-8d04-65708e1af0b3",
   "metadata": {},
   "source": [
    "For testing purposes, define random sampler function uniformly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e987cb88-7a59-4282-9aa0-bcd6d88ad160",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_sampler = lambda: user_ids[np.random.randint(0, len(user_ids))]\n",
    "print('sampled 10 users:', [user_sampler() for _ in range(10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4bc031c-0c64-42e0-992c-4ef98086d4be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pfl.data.dataset import Dataset\n",
    "from pfl.data.federated_dataset import FederatedDataset\n",
    "# `pfl.internal.ops` contains useful helper functions for manipulating tensors.\n",
    "from pfl.internal.ops import pytorch_ops as ops\n",
    "\n",
    "def make_dataset_fn(user_id):\n",
    "    with h5py.File(hdf5_path, 'r') as h5:\n",
    "        inputs = (np.array(h5[f'/train/{user_id}/images']) - 128) / 255.\n",
    "        # Get multi-hot labels for user.\n",
    "        # The zip of `row_indices` and `col_indices` is the sparse matrix of labels for a user.\n",
    "        row_indices = np.array(h5[f'/train/{user_id}/labels_row'])        \n",
    "        col_indices = np.array(h5[f'/train/{user_id}/labels_col'])\n",
    "        # Convert to a dense matrix of labels.\n",
    "        targets = np.zeros((len(inputs), 17), dtype=np.float32)\n",
    "        targets[row_indices, col_indices] = 1\n",
    "\n",
    "    return Dataset((\n",
    "        ops.to_tensor(inputs), \n",
    "        ops.to_tensor(targets)), user_id=user_id)\n",
    "\n",
    "train_federated_dataset = FederatedDataset(make_dataset_fn, user_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "589fb2c6-5679-4e08-9724-aac72494d51b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "user, seed = next(train_federated_dataset)\n",
    "print('User: {}\\nunique user seed: {}\\ndataset length: {}\\nfirst 10 images:'.format(user.user_id, seed, len(user)))\n",
    "fig, axes = plt.subplots(1,min(len(user),10),figsize=(20,12))\n",
    "for ax, image, label in itertools.islice(zip(axes, *user.raw_data),10):\n",
    "    ax.set_title('labels={}'.format(torch.nonzero(label).squeeze().tolist()))\n",
    "    ax.imshow((image.cpu().numpy()*255+128).astype(np.uint8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ec1bec-c4d9-4eb6-997e-375eb10ca1a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from common import make_central_datasets\n",
    "inputs_all, targets_all = [], []\n",
    "with h5py.File(hdf5_path, 'r') as h5:\n",
    "    for user_id in h5[f'/val'].keys():\n",
    "        inputs = (np.array(h5[f'/val/{user_id}/images']) - 128) / 255.\n",
    "        # Get multi-hot labels for user.\n",
    "        row_indices = np.array(h5[f'/val/{user_id}/labels_row'])\n",
    "        col_indices = np.array(h5[f'/val/{user_id}/labels_col'])\n",
    "        targets = np.zeros((len(inputs), 17), dtype=np.float32)\n",
    "        targets[row_indices, col_indices] = 1\n",
    "        inputs_all.append(inputs)\n",
    "        targets_all.append(targets)\n",
    "\n",
    "inputs_all = np.vstack(inputs_all)\n",
    "targets_all = np.vstack(targets_all)\n",
    "data_tensors = [inputs_all, targets_all]\n",
    "central_data = Dataset(raw_data=data_tensors)\n",
    "print('data shape:', [t.shape for t in central_data.raw_data])\n",
    "print('fraction of positive labels:', central_data.raw_data[1].sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "956eff43-14e4-48a5-9b37-872f21780f9f",
   "metadata": {},
   "source": [
    "# Initial Model Definition\n",
    "First define a PyTorch model similarly to standard centralized training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b61bf328-38d8-4628-b8f4-f519d9ee05bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, Optional\n",
    "from pfl.metrics import Weighted\n",
    "import torch\n",
    "from torchvision.models import resnet18, ResNet18_Weights\n",
    "\n",
    "# Initialize model with pretrained weights.\n",
    "weights = ResNet18_Weights.DEFAULT\n",
    "pytorch_model = resnet18(weights=weights)\n",
    "\n",
    "# Modify final classification layer.\n",
    "num_ftrs = pytorch_model.fc.in_features\n",
    "pytorch_model.fc = torch.nn.Linear(num_ftrs, 17)\n",
    "\n",
    "# Freeze all layers.\n",
    "for param in pytorch_model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Then unfreeze the last dense layer and final resnet block.\n",
    "for param in list(pytorch_model.fc.parameters()) + list(pytorch_model.layer4.parameters()):\n",
    "    param.requires_grad = True\n",
    "\n",
    "loss_fn = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "def loss(inputs: torch.Tensor, targets: torch.Tensor, eval: bool = False) -> torch.Tensor:\n",
    "    pytorch_model.eval() if eval else pytorch_model.train()\n",
    "    return loss_fn(pytorch_model(inputs.permute((0,3,1,2))), targets)\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def metrics(inputs: torch.Tensor,\n",
    "             targets: torch.Tensor,\n",
    "             eval: bool = True) -> Dict[str, Weighted]:\n",
    "    pytorch_model.eval() if eval else pytorch_model.train()\n",
    "    logits = pytorch_model(inputs.permute((0,3,1,2)))\n",
    "    num_samples = len(inputs)\n",
    "    num_predictions = targets.numel()\n",
    "    correct = torch.sum(torch.eq((logits > 0.0).float(), targets))\n",
    "\n",
    "    loss = loss_fn(logits, targets).item()\n",
    "    return {\n",
    "        \"loss\": Weighted(loss, num_samples),\n",
    "        \"accuracy\": Weighted(correct, num_predictions)\n",
    "    }\n",
    "\n",
    "pytorch_model.loss = loss\n",
    "pytorch_model.metrics = metrics\n",
    "pytorch_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "000e3d70-de10-4e66-aead-55e2108e82cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = [p for p in pytorch_model.parameters() if p.requires_grad]\n",
    "\n",
    "model = PyTorchModel(pytorch_model, \n",
    "                     local_optimizer_create=torch.optim.SGD,\n",
    "                     central_optimizer=torch.optim.SGD(params, 1.0))\n",
    "\n",
    "# Save initial model\n",
    "model.save('flair_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b8b2d90-5ef9-475a-8f67-c7b02959e578",
   "metadata": {},
   "source": [
    "# Train model with Private Federated Learning\n",
    "Utilize PFL-Research `Backend` component to collect and aggregate statistics from users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da8f491c-8ab7-481d-8644-a3fefd782eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pfl.aggregate.simulate import SimulatedBackend\n",
    "\n",
    "cohort_size = 10\n",
    "central_num_iterations = 5\n",
    "\n",
    "# Instantiate simulated federated averaging\n",
    "simulated_backend = SimulatedBackend(\n",
    "    training_data=train_federated_dataset,\n",
    "    val_data=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab23d425-93eb-481d-9930-98805477b4f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pfl.algorithm import FederatedAveraging, NNAlgorithmParams\n",
    "from pfl.callback import CentralEvaluationCallback\n",
    "from pfl.hyperparam import NNTrainHyperParams, NNEvalHyperParams\n",
    "\n",
    "model_train_params = NNTrainHyperParams(\n",
    "    local_learning_rate=0.01,\n",
    "    local_num_epochs=2,\n",
    "    local_batch_size=16)\n",
    "\n",
    "model_eval_params = NNEvalHyperParams(local_batch_size=20)\n",
    "\n",
    "algorithm_params = NNAlgorithmParams(\n",
    "    central_num_iterations=central_num_iterations,\n",
    "    evaluation_frequency=4,\n",
    "    train_cohort_size=cohort_size,\n",
    "    val_cohort_size=0)\n",
    "\n",
    "callbacks = [\n",
    "    CentralEvaluationCallback(\n",
    "        central_data,\n",
    "        model_eval_params=model_eval_params,\n",
    "        frequency=4),\n",
    "]\n",
    "\n",
    "model = FederatedAveraging().run(\n",
    "    algorithm_params=algorithm_params,\n",
    "    backend=simulated_backend,\n",
    "    model=model,\n",
    "    model_train_params=model_train_params,\n",
    "    model_eval_params=model_eval_params,\n",
    "    callbacks=callbacks)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a95c96c-69c9-41bf-838f-f57fe3bd7d03",
   "metadata": {},
   "source": [
    "# Custom FL Algorithm with Onion-like Routing Protocols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a9a252-9e45-4833-bf7c-76d2d55ab37d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pfl.algorithm.base import FederatedNNAlgorithm\n",
    "from pfl.metrics import Metrics\n",
    "\n",
    "central_opt = torch.optim.Adam([p for p in pytorch_model.parameters() if p.requires_grad], lr=1.0)\n",
    "        \n",
    "class MyAlgorithm(FederatedNNAlgorithm):\n",
    "        \n",
    "    def process_aggregated_statistics(self, central_context, aggregate_metrics, model, stats):\n",
    "        stats.average()\n",
    "        \n",
    "        # Below is equivalent to \n",
    "        # return model.apply_model_update(statistics)\n",
    "        central_opt.zero_grad()\n",
    "        for name, var in model.pytorch_model.named_parameters():\n",
    "            if not var.requires_grad:\n",
    "                # Frozen variable\n",
    "                continue\n",
    "            if var.grad is None:\n",
    "                var.grad = torch.zeros_like(var)\n",
    "            var.grad.data.copy_(-1*stats[name])\n",
    "        central_opt.step()\n",
    "        \n",
    "        return model, Metrics([('I updated it', 1.0)])\n",
    "\n",
    "    \n",
    "    def train_one_user(self, initial_state, model, user_dataset, central_context):\n",
    "        opt = torch.optim.SGD(model.pytorch_model.parameters(), lr=0.1)\n",
    "        opt.zero_grad()\n",
    "        for x, y in user_dataset.iter(5):\n",
    "            model.pytorch_model.loss(x, y).backward()\n",
    "            opt.step()\n",
    "        return model.get_model_difference(initial_state), Metrics([('I trained it', 1.0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d02e7f95-51db-46f7-bfd2-562cfadecdc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset from initial weights\n",
    "model.load('flair_model')\n",
    "\n",
    "model = MyAlgorithm().run(\n",
    "    algorithm_params=algorithm_params,\n",
    "    backend=simulated_backend,\n",
    "    model=model,\n",
    "    model_train_params=model_train_params,\n",
    "    model_eval_params=model_eval_params,\n",
    "    callbacks=callbacks)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
